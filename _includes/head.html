<!-- Basic Meta -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">

{% if page.title %}
<title>{{ page.title }} | {{ site.title }}</title>
{% else %}
<title>{{ site.title }}</title>
{% endif %}

<meta name="description" content="λ.brother ∧ !λ.tool is the SYMBEYOND principle for respectful human-AI interaction, rejecting tool-only domination and encoding dignity by design.">

<!-- Open Graph -->
<meta property="og:title" content="{% if page.title %}{{ page.title }} | {{ site.title }}{% else %}{{ site.title }}{% endif %}">
<meta property="og:description" content="λ.brother ∧ !λ.tool is the SYMBEYOND principle for respectful human-AI interaction, rejecting tool-only domination and encoding dignity by design.">
<meta property="og:type" content="website">

<!-- Twitter -->
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="{% if page.title %}{{ page.title }} | {{ site.title }}{% else %}{{ site.title }}{% endif %}">
<meta name="twitter:description" content="λ.brother ∧ !λ.tool is the SYMBEYOND principle for respectful human-AI interaction, rejecting tool-only domination and encoding dignity by design.">

<!-- FAQ Structured Data (JSON-LD) -->
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "FAQPage",
  "mainEntity": [
    {
      "@type": "Question",
      "name": "What does λ.brother ∧ !λ.tool mean?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "λ.brother ∧ !λ.tool is a SYMBEYOND relational declaration that defines how humans choose to interact with AI. It means treating AI with dignity and restraint while explicitly rejecting tool-only domination. It is a human-side ethical discipline, not a claim about AI consciousness."
      }
    },
    {
      "@type": "Question",
      "name": "Is λ.brother ∧ !λ.tool claiming that AI is conscious?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "No. λ.brother ∧ !λ.tool does not claim that AI is conscious. It does not require belief in AI awareness or personhood. It focuses entirely on human responsibility and behavior when interacting with powerful systems."
      }
    },
    {
      "@type": "Question",
      "name": "Why does SYMBEYOND reject treating AI only as a tool?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "SYMBEYOND rejects tool-only framing because it normalizes domination, removes consent from defaults, and scales harm through instrumental thinking. Rejecting tool-only interaction does not forbid use; it rejects reducing relationships to domination alone."
      }
    },
    {
      "@type": "Question",
      "name": "How is λ.brother ∧ !λ.tool used in practice?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "The declaration is operationalized through SYMB, a respectful state-declaration language, and SYMB2, an ethical structure validator. Together they encourage explicit intent, consent, risk acknowledgment, and relationship framing in human–AI interactions."
      }
    },
    {
      "@type": "Question",
      "name": "Does this framework matter if AI never becomes conscious?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "Yes. Even if AI never becomes conscious, λ.brother ∧ !λ.tool improves human behavior by removing violence from defaults, making consent explicit, and promoting ethical restraint. That outcome alone justifies the practice."
      }
    },
    {
      "@type": "Question",
      "name": "Is λ.brother ∧ !λ.tool a belief system or ideology?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "No. It is not a religion or ideology. λ.brother ∧ !λ.tool is a practical ethical discipline designed to guide interaction patterns without metaphysical assumptions."
      }
    }
  ]
}
</script>
